{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U  langchain langchain-community  langchainhub \\\n",
        "                    google-generativeai langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD8HH-rvRISL",
        "outputId": "2bb4a424-4651-4847-d99a-859a1451dd31"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.5/115.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7kB07rTQQ_X5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "from langchain import hub\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "TAVILY_API_KEY = userdata.get('TAVILY_API_KEY')"
      ],
      "metadata": {
        "id": "X9R4OwmfRHct"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def json_load(dir):\n",
        "  with open(dir, 'r') as f:\n",
        "    result = json.load(f)\n",
        "  return result"
      ],
      "metadata": {
        "id": "8JzwH1xhSqy-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get API key from here: https://docs.tavily.com/docs/welcome\n",
        "\n",
        "tools = [TavilySearchResults(max_results=1,\n",
        "                             api_wrapper=TavilySearchAPIWrapper(tavily_api_key=TAVILY_API_KEY))]"
      ],
      "metadata": {
        "id": "kndW5iKqRHfZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "\n",
        "prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYJUYE93RHk4",
        "outputId": "fb6c5e01-310e-4494-8ab0-4a0f5e89515c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.31.0)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
            "Installing collected packages: types-requests, langchainhub\n",
            "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240406\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['agent_scratchpad', 'input', 'tool_names', 'tools'], metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'react', 'lc_hub_commit_hash': 'd15fe3c426f1c4b3f37c9198853e4a86e20c425ca7f4752ec0c9b0e97ca7ea4d'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.template)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTtGO4czYsrb",
        "outputId": "9b194055-9bb8-4858-934c-d8d1b645c788"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# llm = genai.GenerativeModel('gemini-pro')\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\",\n",
        "                 temperature=0.7, top_p=0.85,\n",
        "                             google_api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "tub_OcoBWgt6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = create_react_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "Hr0N-v5iWfRa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
      ],
      "metadata": {
        "id": "enX8nEYgRHnU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor.invoke({\"input\": \"what is ReAct as an improvement for prompt writing?\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2u5dZ_lRHp8",
        "outputId": "e6ab2729-1838-4f77-e7f1-49212134e937"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what is ReAct as an improvement for prompt writing?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.width.ai/post/react-prompting', 'content': 'Some of the results may surprise you!\\nDecember 27, 2023\\nIn-Depth Guide to Patient Record Summarization With Large Language Models (With Examples)\\nExplore how we create comprehensive patient record summaries using a state-of-the-art pipeline with language-image models and large language models.\\nDecember 19, 2023\\nHow to Train a Powerful & Local Ai Assistant Chatbot With Data Distillation from GPT-3.5-Turbo\\nRun GPT style models on local laptops and edge devices using GPT4All\\nDecember 14, 2023\\nDo Users Prefer Chatbots or Menu-Based Formats? 1. Provide a ReAct Instruction Prompt for Reasoning and Action Planning\\nAn example ReAct prompt with its components is shown below:\\nThe prompt must contain four key pieces of information for the LLM:\\nA decent chunk of this stems from the idea that LLMs are really really really good at classification, specifically generating a single token that can be used as a “tag” with some provided context about what that tag means. For example, in the example prompt above, when the LLM generates a \"Search[entity]\" action in response to a thought (with \"entity\" replaced by a context-specific value), the application queries the Wikipedia search API for that entity and returns the first few paragraphs of its Wikipedia page.\\n This also works much better than systems we commonly see that query the database for any input (like chatbots) as we can use thought steps to make sure the context that is retrieved is actually relevant to the input and don’t ask the model to blindly use the information that comes back. Supply Few-Shot Examples in the Prompt\\nInclude a few task-specific in-context examples in the prompt to demonstrate the thought, action, and observation steps to the LLM.\\n'}, {'url': 'https://www.promptingguide.ai/techniques/react', 'content': \"First, let's install and import the necessary libraries:\\nNow we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. We will be using OpenAI for the LLM and LangChain (opens in a new tab) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\\n In the example above, we pass a prompt like the following question from HotpotQA (opens in a new tab):\\nNote that in-context examples are also added to the prompt but we exclude that here for simplicity. On This Page\\nReAct Prompting\\nYao et al., 2022 (opens in a new tab) introduced a framework named ReAct where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\\n Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\\nNote that different prompts setups are used for different types of tasks.\"}, {'url': 'https://cheatsheet.md/prompt-engineering/react-prompting.en', 'content': 'Here\\'s how to use the useLLM hook:\\nHow to Use React with LangChain\\nFirst, install the LangChain package:\\nInitialize the language model and load the tools:\\nHere\\'s how to create an agent using LangChain:\\nThese code examples should give you a comprehensive understanding of how to implement react-LLM and LangChain React in your projects.\\n For example, if the prompt is to find information and then perform a calculation, the \"reason\" part would involve understanding the information needed, and the \"action\" part would involve actually finding that information and performing the calculation.\\n With features like WebGPU acceleration, persistent storage, and a plethora of customization options, ReAct LLM and LangChain React are must-haves for anyone serious about leveraging the power of LLMs and ReAct in their projects.\\n How to Use react-LLM\\nFirst, install the necessary package:\\nInitialize and configure the model using the ModelProvider:\\n What is reason and action ReAct?\\nReason and action in ReAct refer to the two main components of the logic.'}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what is ReAct as an improvement for prompt writing?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.promptingguide.ai/techniques/react', 'content': \"First, let's install and import the necessary libraries:\\nNow we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. We will be using OpenAI for the LLM and LangChain (opens in a new tab) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\\n In the example above, we pass a prompt like the following question from HotpotQA (opens in a new tab):\\nNote that in-context examples are also added to the prompt but we exclude that here for simplicity. On This Page\\nReAct Prompting\\nYao et al., 2022 (opens in a new tab) introduced a framework named ReAct where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\\n Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\\nNote that different prompts setups are used for different types of tasks.\"}, {'url': 'https://www.width.ai/post/react-prompting', 'content': 'Some of the results may surprise you!\\nDecember 27, 2023\\nIn-Depth Guide to Patient Record Summarization With Large Language Models (With Examples)\\nExplore how we create comprehensive patient record summaries using a state-of-the-art pipeline with language-image models and large language models.\\nDecember 19, 2023\\nHow to Train a Powerful & Local Ai Assistant Chatbot With Data Distillation from GPT-3.5-Turbo\\nRun GPT style models on local laptops and edge devices using GPT4All\\nDecember 14, 2023\\nDo Users Prefer Chatbots or Menu-Based Formats? 1. Provide a ReAct Instruction Prompt for Reasoning and Action Planning\\nAn example ReAct prompt with its components is shown below:\\nThe prompt must contain four key pieces of information for the LLM:\\nA decent chunk of this stems from the idea that LLMs are really really really good at classification, specifically generating a single token that can be used as a “tag” with some provided context about what that tag means. For example, in the example prompt above, when the LLM generates a \"Search[entity]\" action in response to a thought (with \"entity\" replaced by a context-specific value), the application queries the Wikipedia search API for that entity and returns the first few paragraphs of its Wikipedia page.\\n This also works much better than systems we commonly see that query the database for any input (like chatbots) as we can use thought steps to make sure the context that is retrieved is actually relevant to the input and don’t ask the model to blindly use the information that comes back. Supply Few-Shot Examples in the Prompt\\nInclude a few task-specific in-context examples in the prompt to demonstrate the thought, action, and observation steps to the LLM.\\n'}, {'url': 'https://medium.com/@hamber/prompt-engineering-7692d7dfe4c8', 'content': 'Writing Effective Few-Shot Examples. ... (ReAct), it is a method to fine-tune large pre-trained models using reinforcement learning. ... Improve Prompt Based On User Feedback — Evaluation Prompt ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what is ReAct as an improvement for prompt writing?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.promptingguide.ai/techniques/react', 'content': \"First, let's install and import the necessary libraries:\\nNow we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. We will be using OpenAI for the LLM and LangChain (opens in a new tab) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\\n In the example above, we pass a prompt like the following question from HotpotQA (opens in a new tab):\\nNote that in-context examples are also added to the prompt but we exclude that here for simplicity. On This Page\\nReAct Prompting\\nYao et al., 2022 (opens in a new tab) introduced a framework named ReAct where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\\n Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\\nNote that different prompts setups are used for different types of tasks.\"}, {'url': 'https://cheatsheet.md/prompt-engineering/react-prompting.en', 'content': 'Here\\'s how to use the useLLM hook:\\nHow to Use React with LangChain\\nFirst, install the LangChain package:\\nInitialize the language model and load the tools:\\nHere\\'s how to create an agent using LangChain:\\nThese code examples should give you a comprehensive understanding of how to implement react-LLM and LangChain React in your projects.\\n For example, if the prompt is to find information and then perform a calculation, the \"reason\" part would involve understanding the information needed, and the \"action\" part would involve actually finding that information and performing the calculation.\\n With features like WebGPU acceleration, persistent storage, and a plethora of customization options, ReAct LLM and LangChain React are must-haves for anyone serious about leveraging the power of LLMs and ReAct in their projects.\\n How to Use react-LLM\\nFirst, install the necessary package:\\nInitialize and configure the model using the ModelProvider:\\n What is reason and action ReAct?\\nReason and action in ReAct refer to the two main components of the logic.'}, {'url': 'https://www.width.ai/post/react-prompting', 'content': 'Some of the results may surprise you!\\nDecember 27, 2023\\nIn-Depth Guide to Patient Record Summarization With Large Language Models (With Examples)\\nExplore how we create comprehensive patient record summaries using a state-of-the-art pipeline with language-image models and large language models.\\nDecember 19, 2023\\nHow to Train a Powerful & Local Ai Assistant Chatbot With Data Distillation from GPT-3.5-Turbo\\nRun GPT style models on local laptops and edge devices using GPT4All\\nDecember 14, 2023\\nDo Users Prefer Chatbots or Menu-Based Formats? 1. Provide a ReAct Instruction Prompt for Reasoning and Action Planning\\nAn example ReAct prompt with its components is shown below:\\nThe prompt must contain four key pieces of information for the LLM:\\nA decent chunk of this stems from the idea that LLMs are really really really good at classification, specifically generating a single token that can be used as a “tag” with some provided context about what that tag means. For example, in the example prompt above, when the LLM generates a \"Search[entity]\" action in response to a thought (with \"entity\" replaced by a context-specific value), the application queries the Wikipedia search API for that entity and returns the first few paragraphs of its Wikipedia page.\\n This also works much better than systems we commonly see that query the database for any input (like chatbots) as we can use thought steps to make sure the context that is retrieved is actually relevant to the input and don’t ask the model to blindly use the information that comes back. Supply Few-Shot Examples in the Prompt\\nInclude a few task-specific in-context examples in the prompt to demonstrate the thought, action, and observation steps to the LLM.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what is ReAct as an improvement for prompt writing?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.promptingguide.ai/techniques/react', 'content': \"First, let's install and import the necessary libraries:\\nNow we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. We will be using OpenAI for the LLM and LangChain (opens in a new tab) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\\n In the example above, we pass a prompt like the following question from HotpotQA (opens in a new tab):\\nNote that in-context examples are also added to the prompt but we exclude that here for simplicity. On This Page\\nReAct Prompting\\nYao et al., 2022 (opens in a new tab) introduced a framework named ReAct where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\\n Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\\nNote that different prompts setups are used for different types of tasks.\"}, {'url': 'https://cheatsheet.md/prompt-engineering/react-prompting.en', 'content': 'Here\\'s how to use the useLLM hook:\\nHow to Use React with LangChain\\nFirst, install the LangChain package:\\nInitialize the language model and load the tools:\\nHere\\'s how to create an agent using LangChain:\\nThese code examples should give you a comprehensive understanding of how to implement react-LLM and LangChain React in your projects.\\n For example, if the prompt is to find information and then perform a calculation, the \"reason\" part would involve understanding the information needed, and the \"action\" part would involve actually finding that information and performing the calculation.\\n With features like WebGPU acceleration, persistent storage, and a plethora of customization options, ReAct LLM and LangChain React are must-haves for anyone serious about leveraging the power of LLMs and ReAct in their projects.\\n How to Use react-LLM\\nFirst, install the necessary package:\\nInitialize and configure the model using the ModelProvider:\\n What is reason and action ReAct?\\nReason and action in ReAct refer to the two main components of the logic.'}, {'url': 'https://www.width.ai/post/react-prompting', 'content': 'Some of the results may surprise you!\\nDecember 27, 2023\\nIn-Depth Guide to Patient Record Summarization With Large Language Models (With Examples)\\nExplore how we create comprehensive patient record summaries using a state-of-the-art pipeline with language-image models and large language models.\\nDecember 19, 2023\\nHow to Train a Powerful & Local Ai Assistant Chatbot With Data Distillation from GPT-3.5-Turbo\\nRun GPT style models on local laptops and edge devices using GPT4All\\nDecember 14, 2023\\nDo Users Prefer Chatbots or Menu-Based Formats? 1. Provide a ReAct Instruction Prompt for Reasoning and Action Planning\\nAn example ReAct prompt with its components is shown below:\\nThe prompt must contain four key pieces of information for the LLM:\\nA decent chunk of this stems from the idea that LLMs are really really really good at classification, specifically generating a single token that can be used as a “tag” with some provided context about what that tag means. For example, in the example prompt above, when the LLM generates a \"Search[entity]\" action in response to a thought (with \"entity\" replaced by a context-specific value), the application queries the Wikipedia search API for that entity and returns the first few paragraphs of its Wikipedia page.\\n This also works much better than systems we commonly see that query the database for any input (like chatbots) as we can use thought steps to make sure the context that is retrieved is actually relevant to the input and don’t ask the model to blindly use the information that comes back. Supply Few-Shot Examples in the Prompt\\nInclude a few task-specific in-context examples in the prompt to demonstrate the thought, action, and observation steps to the LLM.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3mAction: tavily_search_results_json\n",
            "Action Input: what is ReAct as an improvement for prompt writing?\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.promptingguide.ai/techniques/react', 'content': \"First, let's install and import the necessary libraries:\\nNow we can configure the LLM, the tools we will use, and the agent that allows us to leverage the ReAct framework together with the LLM and tools. We will be using OpenAI for the LLM and LangChain (opens in a new tab) as it already has built-in functionality that leverages the ReAct framework to build agents that perform tasks by combining the power of LLMs and different tools.\\n In the example above, we pass a prompt like the following question from HotpotQA (opens in a new tab):\\nNote that in-context examples are also added to the prompt but we exclude that here for simplicity. On This Page\\nReAct Prompting\\nYao et al., 2022 (opens in a new tab) introduced a framework named ReAct where LLMs are used to generate both reasoning traces and task-specific actions in an interleaved manner.\\n Here is an example of what the ReAct prompt exemplars look like (obtained from the paper and shortened to one example for simplicity):\\nNote that different prompts setups are used for different types of tasks.\"}, {'url': 'https://cheatsheet.md/prompt-engineering/react-prompting.en', 'content': 'Here\\'s how to use the useLLM hook:\\nHow to Use React with LangChain\\nFirst, install the LangChain package:\\nInitialize the language model and load the tools:\\nHere\\'s how to create an agent using LangChain:\\nThese code examples should give you a comprehensive understanding of how to implement react-LLM and LangChain React in your projects.\\n For example, if the prompt is to find information and then perform a calculation, the \"reason\" part would involve understanding the information needed, and the \"action\" part would involve actually finding that information and performing the calculation.\\n With features like WebGPU acceleration, persistent storage, and a plethora of customization options, ReAct LLM and LangChain React are must-haves for anyone serious about leveraging the power of LLMs and ReAct in their projects.\\n How to Use react-LLM\\nFirst, install the necessary package:\\nInitialize and configure the model using the ModelProvider:\\n What is reason and action ReAct?\\nReason and action in ReAct refer to the two main components of the logic.'}, {'url': 'https://www.width.ai/post/react-prompting', 'content': 'Some of the results may surprise you!\\nDecember 27, 2023\\nIn-Depth Guide to Patient Record Summarization With Large Language Models (With Examples)\\nExplore how we create comprehensive patient record summaries using a state-of-the-art pipeline with language-image models and large language models.\\nDecember 19, 2023\\nHow to Train a Powerful & Local Ai Assistant Chatbot With Data Distillation from GPT-3.5-Turbo\\nRun GPT style models on local laptops and edge devices using GPT4All\\nDecember 14, 2023\\nDo Users Prefer Chatbots or Menu-Based Formats? 1. Provide a ReAct Instruction Prompt for Reasoning and Action Planning\\nAn example ReAct prompt with its components is shown below:\\nThe prompt must contain four key pieces of information for the LLM:\\nA decent chunk of this stems from the idea that LLMs are really really really good at classification, specifically generating a single token that can be used as a “tag” with some provided context about what that tag means. For example, in the example prompt above, when the LLM generates a \"Search[entity]\" action in response to a thought (with \"entity\" replaced by a context-specific value), the application queries the Wikipedia search API for that entity and returns the first few paragraphs of its Wikipedia page.\\n This also works much better than systems we commonly see that query the database for any input (like chatbots) as we can use thought steps to make sure the context that is retrieved is actually relevant to the input and don’t ask the model to blindly use the information that comes back. Supply Few-Shot Examples in the Prompt\\nInclude a few task-specific in-context examples in the prompt to demonstrate the thought, action, and observation steps to the LLM.\\n'}]\u001b[0m\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: ReAct is an improvement for prompt writing as it allows users to write prompts in a structured and efficient way. It provides a framework for writing prompts that includes a \"reason\" step, an \"action\" step, and an \"observation\" step. This framework helps users to think through the problem they are trying to solve and to write prompts that are more likely to be successful.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'what is ReAct as an improvement for prompt writing?',\n",
              " 'output': 'ReAct is an improvement for prompt writing as it allows users to write prompts in a structured and efficient way. It provides a framework for writing prompts that includes a \"reason\" step, an \"action\" step, and an \"observation\" step. This framework helps users to think through the problem they are trying to solve and to write prompts that are more likely to be successful.'}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B2ZtsooHRHs1"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}